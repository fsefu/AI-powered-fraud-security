{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../src')))\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../scripts')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets into DataFrames (make sure you provide the correct path to the files)\n",
    "creditcard_df = pd.read_csv('../data/creditcard.csv')\n",
    "fraud_data_df = pd.read_csv('../data/Fraud_Data.csv')\n",
    "ip_data_df = pd.read_csv('../data/IpAddress_to_Country.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\tutorial\\10x\\tasks\\task_8\\AI-powered-fraud-security\\src\\modelling\\fraud_detection_model.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  self.df[col] = pd.to_datetime(self.df[col])\n",
      "d:\\tutorial\\10x\\tasks\\task_8\\AI-powered-fraud-security\\src\\modelling\\fraud_detection_model.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  self.df[col] = pd.to_datetime(self.df[col])\n",
      "d:\\tutorial\\10x\\tasks\\task_8\\AI-powered-fraud-security\\src\\modelling\\fraud_detection_model.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  self.df[col] = pd.to_datetime(self.df[col])\n",
      "d:\\tutorial\\10x\\tasks\\task_8\\AI-powered-fraud-security\\src\\modelling\\fraud_detection_model.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  self.df[col] = pd.to_datetime(self.df[col])\n"
     ]
    }
   ],
   "source": [
    "# Assuming you've already loaded the fraud dataset into `fraud_data_df` and credit card dataset into `creditcard_df`\n",
    "\n",
    "# Initialize for Fraud Data\n",
    "from modelling.fraud_detection_model import FraudDetectionModel\n",
    "\n",
    "\n",
    "fraud_model = FraudDetectionModel(df=fraud_data_df, target_column='class', experiment_name='Fraud_Data_Experiment')\n",
    "fraud_model.preprocess_data()\n",
    "\n",
    "fraud_model.prepare_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fraud = fraud_model.X_train\n",
    "X_test_fraud = fraud_model.X_test\n",
    "feature_names_fraud = fraud_model.feature_names  # You might need to set this in your FraudDetectionModel class if it's missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression saved successfully as ../model/Logistic Regression_fraud_detection_model.pkl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\tutorial\\10x\\tasks\\task_8\\AI-powered-fraud-security\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024/10/24 21:58:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree saved successfully as ../model/Decision Tree_fraud_detection_model.pkl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 21:59:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest saved successfully as ../model/Random Forest_fraud_detection_model.pkl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 22:00:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting saved successfully as ../model/Gradient Boosting_fraud_detection_model.pkl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 22:01:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP saved successfully as ../model/MLP_fraud_detection_model.pkl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 22:01:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Data Classical Models Results:\n",
      "{'Logistic Regression': {'Accuracy': 0.9057009562253913, 'Precision': 0.0, 'Recall': 0.0, 'F1 Score': 0.0, 'ROC AUC': 0.5}, 'Decision Tree': {'Accuracy': 0.901995169241968, 'Precision': 0.4831223628691983, 'Recall': 0.5624561403508772, 'F1 Score': 0.5197795071335928, 'ROC AUC': 0.749901580568892}, 'Random Forest': {'Accuracy': 0.955861430036727, 'Precision': 0.987146529562982, 'Recall': 0.5389473684210526, 'F1 Score': 0.6972310485701316, 'ROC AUC': 0.7691083607165724}, 'Gradient Boosting': {'Accuracy': 0.9548357211395295, 'Precision': 0.9672750157331655, 'Recall': 0.539298245614035, 'F1 Score': 0.6924983104302771, 'ROC AUC': 0.7686992817227373}, 'MLP': {'Accuracy': 0.9048737716308771, 'Precision': 0.12121212121212122, 'Recall': 0.0014035087719298245, 'F1 Score': 0.002774887270204648, 'ROC AUC': 0.5001720353197318}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train Classical Models\n",
    "results_fraud = fraud_model.train_classical_models()\n",
    "print(\"Fraud Data Classical Models Results:\")\n",
    "print(results_fraud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize for Credit Card Data\n",
    "credit_model = FraudDetectionModel(df=creditcard_df, target_column='Class', experiment_name='CreditCard_Experiment')\n",
    "credit_model.prepare_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\tutorial\\10x\\tasks\\task_8\\AI-powered-fraud-security\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression saved successfully as ../model/Logistic Regression_fraud_detection_model.pkl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 22:02:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree saved successfully as ../model/Decision Tree_fraud_detection_model.pkl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 22:02:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest saved successfully as ../model/Random Forest_fraud_detection_model.pkl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 22:09:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting saved successfully as ../model/Gradient Boosting_fraud_detection_model.pkl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 22:17:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP saved successfully as ../model/MLP_fraud_detection_model.pkl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 22:19:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Card Data Classical Models Results:\n",
      "{'Logistic Regression': {'Accuracy': 0.9986306660580738, 'Precision': 0.6111111111111112, 'Recall': 0.5612244897959183, 'F1 Score': 0.5851063829787234, 'ROC AUC': 0.7803044930690339}, 'Decision Tree': {'Accuracy': 0.9989642217618764, 'Precision': 0.6666666666666666, 'Recall': 0.7959183673469388, 'F1 Score': 0.7255813953488373, 'ROC AUC': 0.8976162602069528}, 'Random Forest': {'Accuracy': 0.9996137776061234, 'Precision': 0.9871794871794872, 'Recall': 0.7857142857142857, 'F1 Score': 0.875, 'ROC AUC': 0.892848349947745}, 'Gradient Boosting': {'Accuracy': 0.9989466661985184, 'Precision': 0.7375, 'Recall': 0.6020408163265306, 'F1 Score': 0.6629213483146067, 'ROC AUC': 0.8008357570659101}, 'MLP': {'Accuracy': 0.9984024437344194, 'Precision': 0.6296296296296297, 'Recall': 0.17346938775510204, 'F1 Score': 0.272, 'ROC AUC': 0.5866467647835725}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train Classical Models\n",
    "results_credit = credit_model.train_classical_models()\n",
    "print(\"Credit Card Data Classical Models Results:\")\n",
    "print(results_credit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\tutorial\\10x\\tasks\\task_8\\AI-powered-fraud-security\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8282 - loss: 2525188.7500 - val_accuracy: 0.9056 - val_loss: 522197.9062\n",
      "Epoch 2/10\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8326 - loss: 672354.3750 - val_accuracy: 0.8753 - val_loss: 4256.4746\n",
      "Epoch 3/10\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8300 - loss: 302601.2812 - val_accuracy: 0.9062 - val_loss: 81601.1406\n",
      "Epoch 4/10\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8343 - loss: 144917.5938 - val_accuracy: 0.9068 - val_loss: 173272.9688\n",
      "Epoch 5/10\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8290 - loss: 65240.1172 - val_accuracy: 0.9067 - val_loss: 55729.2969\n",
      "Epoch 6/10\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8315 - loss: 26879.9395 - val_accuracy: 0.9067 - val_loss: 16102.4746\n",
      "Epoch 7/10\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8276 - loss: 10213.4697 - val_accuracy: 0.9067 - val_loss: 247.4308\n",
      "Epoch 8/10\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8665 - loss: 474.9492 - val_accuracy: 0.9068 - val_loss: 0.3298\n",
      "Epoch 9/10\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9054 - loss: 0.3223 - val_accuracy: 0.9068 - val_loss: 0.3102\n",
      "Epoch 10/10\n",
      "\u001b[1m3023/3023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9059 - loss: 0.3124 - val_accuracy: 0.9068 - val_loss: 0.3100\n",
      "\u001b[1m945/945\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.3045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Fraud saved successfully as ../model/CNN_Fraud_fraud_detection_model.h5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 22:20:54 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/10/24 22:21:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Model Results for Fraud Data:\n",
      "{'Loss': 0.3123808205127716, 'Accuracy': 0.9057009816169739}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train CNN for Fraud Data\n",
    "cnn_model_fraud = fraud_model.create_cnn_model(input_shape=(fraud_model.X_train.shape[1], 1))\n",
    "cnn_results_fraud = fraud_model.train_deep_learning_model('CNN_Fraud', cnn_model_fraud)\n",
    "print(\"CNN Model Results for Fraud Data:\")\n",
    "print(cnn_results_fraud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\tutorial\\10x\\tasks\\task_8\\AI-powered-fraud-security\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 14ms/step - accuracy: 0.9746 - loss: 141.3395 - val_accuracy: 0.9981 - val_loss: 2.8697\n",
      "Epoch 2/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 13ms/step - accuracy: 0.9971 - loss: 1.2101 - val_accuracy: 0.9981 - val_loss: 1.8308\n",
      "Epoch 3/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 14ms/step - accuracy: 0.9962 - loss: 9.6531 - val_accuracy: 0.9981 - val_loss: 2.6964\n",
      "Epoch 4/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 13ms/step - accuracy: 0.9972 - loss: 1.9474 - val_accuracy: 0.9981 - val_loss: 5.9254\n",
      "Epoch 5/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 13ms/step - accuracy: 0.9966 - loss: 5.6358 - val_accuracy: 0.9981 - val_loss: 1.3595\n",
      "Epoch 6/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 13ms/step - accuracy: 0.9965 - loss: 11.2073 - val_accuracy: 0.9981 - val_loss: 3.0314\n",
      "Epoch 7/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 13ms/step - accuracy: 0.9968 - loss: 216.0314 - val_accuracy: 0.9981 - val_loss: 99.6581\n",
      "Epoch 8/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 12ms/step - accuracy: 0.9963 - loss: 95.7533 - val_accuracy: 0.9981 - val_loss: 6.8330\n",
      "Epoch 9/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 12ms/step - accuracy: 0.9966 - loss: 15.4116 - val_accuracy: 0.9981 - val_loss: 19.2375\n",
      "Epoch 10/10\n",
      "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 12ms/step - accuracy: 0.9978 - loss: 90.9426 - val_accuracy: 0.9947 - val_loss: 0.5408\n",
      "\u001b[1m1781/1781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.4910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_Credit saved successfully as ../model/LSTM_Credit_fraud_detection_model.h5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 22:33:27 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/10/24 22:33:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Model Results for Credit Card Data:\n",
      "{'Loss': 0.5136203765869141, 'Accuracy': 0.9949264526367188}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train LSTM for Credit Card Data\n",
    "lstm_model_credit = credit_model.create_lstm_model(input_shape=(credit_model.X_train.shape[1], 1))\n",
    "lstm_results_credit = credit_model.train_deep_learning_model('LSTM_Credit', lstm_model_credit)\n",
    "print(\"LSTM Model Results for Credit Card Data:\")\n",
    "print(lstm_results_credit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Explainabilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "class ModelExplainability:\n",
    "    def __init__(self, model_path, X_train, X_test, feature_names, model_type=\"tree\"):\n",
    "        \"\"\"\n",
    "        Initialize with the model path, training data, test data, and feature names.\n",
    "        :param model_path: Path to the saved model\n",
    "        :param X_train: Training data (used to fit SHAP or LIME explainers)\n",
    "        :param X_test: Test data (used for generating explanations)\n",
    "        :param feature_names: List of feature names (important for LIME and SHAP plots)\n",
    "        :param model_type: Type of model ('tree' for tree-based, 'blackbox' for other models)\n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.feature_names = feature_names\n",
    "        self.model = self.load_model(model_path)\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"\n",
    "        Load the saved model based on the type.\n",
    "        :param model_path: Path to the saved model file\n",
    "        :return: Loaded model\n",
    "        \"\"\"\n",
    "        if self.model_type in ['tree', 'classical']:\n",
    "            return joblib.load(model_path)\n",
    "        elif self.model_type == 'blackbox' or self.model_type == 'deep_learning':\n",
    "            return load_model(model_path)\n",
    "\n",
    "    def shap_explain(self):\n",
    "        \"\"\"\n",
    "        Use SHAP to explain model predictions.\n",
    "        Provides summary, force, and dependence plots.\n",
    "        \"\"\"\n",
    "        # Initialize SHAP explainer based on model type\n",
    "        if self.model_type == \"tree\":\n",
    "            explainer = shap.TreeExplainer(self.model, feature_perturbation='interventional')\n",
    "        else:\n",
    "            explainer = shap.KernelExplainer(self.model.predict_proba, self.X_train)\n",
    "        \n",
    "        # Calculate SHAP values for test data\n",
    "        try:\n",
    "            shap_values = explainer.shap_values(self.X_test, check_additivity=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating SHAP values: {e}\")\n",
    "            return\n",
    "        \n",
    "        # SHAP Summary Plot (for global explanation)\n",
    "        shap.summary_plot(shap_values[1], self.X_test, feature_names=self.feature_names)\n",
    "        plt.show()\n",
    "\n",
    "        # SHAP Force Plot (for a single prediction explanation)\n",
    "        shap.force_plot(explainer.expected_value[1], shap_values[1][0, :], self.X_test.iloc[0, :], matplotlib=True)\n",
    "        plt.show()\n",
    "\n",
    "        # SHAP Dependence Plot (for specific feature vs model output)\n",
    "        shap.dependence_plot(0, shap_values[1], self.X_test, feature_names=self.feature_names)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # def shap_explain(self):\n",
    "    #     \"\"\"\n",
    "    #     Use SHAP to explain model predictions.\n",
    "    #     Provides summary, force, and dependence plots.\n",
    "    #     \"\"\"\n",
    "    #     # Initialize SHAP explainer based on model type\n",
    "    #     if self.model_type == \"tree\":\n",
    "    #         explainer = shap.TreeExplainer(self.model)\n",
    "    #     else:\n",
    "    #         explainer = shap.KernelExplainer(self.model.predict_proba, self.X_train)\n",
    "        \n",
    "    #     # Calculate SHAP values for test data\n",
    "    #     shap_values = explainer.shap_values(self.X_test, check_additivity=False)\n",
    "        \n",
    "    #     # SHAP Summary Plot (for global explanation)\n",
    "    #     shap.summary_plot(shap_values[1], self.X_test, feature_names=self.feature_names)\n",
    "    #     plt.show()\n",
    "\n",
    "    #     # SHAP Force Plot (for a single prediction explanation)\n",
    "    #     shap.force_plot(explainer.expected_value[1], shap_values[1][0, :], self.X_test.iloc[0, :], matplotlib=True)\n",
    "    #     plt.show()\n",
    "\n",
    "    #     # SHAP Dependence Plot (for specific feature vs model output)\n",
    "    #     shap.dependence_plot(0, shap_values[1], self.X_test, feature_names=self.feature_names)\n",
    "    #     plt.show()\n",
    "\n",
    "    def lime_explain(self, instance_idx=0):\n",
    "        \"\"\"\n",
    "        Use LIME to explain a single prediction.\n",
    "        :param instance_idx: Index of the instance to explain (default is 0)\n",
    "        \"\"\"\n",
    "        # Initialize LIME explainer\n",
    "        explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "            training_data=self.X_train.values, \n",
    "            feature_names=self.feature_names, \n",
    "            class_names=[\"Not Fraud\", \"Fraud\"],\n",
    "            mode='classification'\n",
    "        )\n",
    "        \n",
    "        # Select an instance from the test set for explanation\n",
    "        instance = self.X_test.iloc[instance_idx]\n",
    "        \n",
    "        # Explain the prediction of the model for the selected instance\n",
    "        explanation = explainer.explain_instance(instance.values, self.model.predict_proba)\n",
    "        \n",
    "        # LIME Feature Importance Plot\n",
    "        explanation.show_in_notebook(show_table=True)\n",
    "\n",
    "    def shap_explain_single(self, instance_idx=0):\n",
    "        \"\"\"\n",
    "        SHAP Force Plot for a single instance.\n",
    "        :param instance_idx: Index of the instance to explain (default is 0)\n",
    "        \"\"\"\n",
    "        # Initialize SHAP explainer\n",
    "        if self.model_type == \"tree\":\n",
    "            explainer = shap.TreeExplainer(self.model, feature_perturbation='interventional')\n",
    "        else:\n",
    "            explainer = shap.KernelExplainer(self.model.predict_proba, self.X_train)\n",
    "        \n",
    "        # Calculate SHAP values for the specific instance\n",
    "        shap_values = explainer.shap_values(self.X_test.iloc[[instance_idx]])\n",
    "        \n",
    "        # SHAP Force Plot for a single prediction\n",
    "        shap.force_plot(explainer.expected_value[1], shap_values[1][0, :], self.X_test.iloc[instance_idx, :], matplotlib=True)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fraud = fraud_model.X_train\n",
    "X_test_fraud = fraud_model.X_test\n",
    "feature_names_fraud = fraud_model.feature_names  # You might need to set this in your FraudDetectionModel class if it's missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ModelExplainability with a saved classical model\n",
    "# from modelling.model_explainability import ModelExplainability\n",
    "\n",
    "\n",
    "model_path_rf = '../model/Random Forest_fraud_detection_model.pkl'\n",
    "explain_rf = ModelExplainability(model_path=model_path_rf, X_train=X_train_fraud, X_test=X_test_fraud, feature_names=feature_names_fraud, model_type='tree')\n",
    "\n",
    "# SHAP explanation\n",
    "explain_rf.shap_explain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize ModelExplainability with a saved deep learning model (CNN)\n",
    "model_path_cnn = '../model/CNN_Fraud_fraud_detection_model.h5'\n",
    "explain_cnn = ModelExplainability(model_path=model_path_cnn, X_train=X_train_fraud, X_test=X_test_fraud, feature_names=feature_names_fraud, model_type='deep_learning')\n",
    "\n",
    "# SHAP explanation for CNN\n",
    "explain_cnn.shap_explain()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
