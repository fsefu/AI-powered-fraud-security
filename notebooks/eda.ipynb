{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../src')))\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../scripts')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets into DataFrames (make sure you provide the correct path to the files)\n",
    "creditcard_df = pd.read_csv('../data/creditcard.csv')\n",
    "fraud_data_df = pd.read_csv('../data/Fraud_Data.csv')\n",
    "ip_data_df = pd.read_csv('../data/IpAddress_to_Country.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize processor\n",
    "from eda.eda import FraudDataProcessor\n",
    "\n",
    "\n",
    "processor = FraudDataProcessor(\n",
    "    creditcard_path=creditcard_df, \n",
    "    fraud_data_path=fraud_data_df, \n",
    "    ip_data_path=ip_data_df\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get minimum age\n",
    "min_age = processor.fraud_data_df['age'].min()\n",
    "\n",
    "# Get maximum age\n",
    "max_age = processor.fraud_data_df['age'].max()\n",
    "\n",
    "print(f\"Minimum Age: {min_age}\")\n",
    "print(f\"Maximum Age: {max_age}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = processor.fraud_data_df['user_id'].unique()\n",
    "print(\"unique: \", unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = processor.fraud_data_df[processor.fraud_data_df.duplicated(subset=['device_id'], keep=False)]\n",
    "\n",
    "# Display the first 20 duplicate rows\n",
    "print(\"First 20 duplicate rows: \\n\", duplicates.head(20))\n",
    "\n",
    "# Count the total number of duplicate rows\n",
    "total_duplicates = duplicates.shape[0]\n",
    "print(\"Total number of duplicate rows: \", total_duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each device_id\n",
    "device_id_counts = processor.fraud_data_df['device_id'].value_counts()\n",
    "\n",
    "# Filter to get only the duplicated device_ids (occurrences > 1)\n",
    "duplicated_device_ids = device_id_counts[device_id_counts > 1]\n",
    "\n",
    "# Print the duplicated device_ids and their counts\n",
    "print(\"Duplicated device_ids and their counts: \\n\", duplicated_device_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show missing values\n",
    "processor.show_missing_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle missing values (impute or drop)\n",
    "processor.handle_missing_values(method='drop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clean the data\n",
    "processor.clean_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View data types and null values for fraud data\n",
    "processor.fraud_data_df.info()\n",
    "\n",
    "# View data types and null values for credit card data\n",
    "processor.creditcard_df.info()\n",
    "\n",
    "# View data types and null values for IP data\n",
    "processor.ip_data_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform EDA\n",
    "processor.univariate_analysis()\n",
    "processor.bivariate_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge datasets\n",
    "merged_data = processor.merge_datasets_for_geolocation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature engineering\n",
    "processed_data = processor.feature_engineering(merged_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize and scale the data\n",
    "scaled_data = processor.normalize_and_scale(processed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode categorical features\n",
    "final_data = processor.encode_categorical_features(scaled_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
